diff --git a/DEPLOYMENT_GUIDE.md b/DEPLOYMENT_GUIDE.md
--- a/DEPLOYMENT_GUIDE.md
+++ b/DEPLOYMENT_GUIDE.md
@@ -0,0 +1,911 @@
+# Deployment Guide
+
+## Overview
+
+–¢–æ–∑–∏ –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å–≤–∞ –∫–∞–∫ –¥–∞ –¥–µ–ø–ª–æ–π–Ω–µ—Ç–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ä–µ–¥–∏ - development, staging –∏ production.
+
+---
+
+## Development Environment
+
+### Prerequisites
+
+- Docker Desktop (latest)
+- Node.js 20+
+- Python 3.11+
+- Git
+
+### Initial Setup
+
+```bash
+# Clone repository
+git clone <repo-url>
+cd business-requirements-ai-system
+
+# Copy environment files
+cp .env.example .env.dev
+
+# Edit .env.dev with your settings
+# - OpenAI API key
+# - Database credentials
+# - Redis settings
+```
+
+### Docker Compose Development
+
+```yaml
+# docker-compose.dev.yml
+version: '3.8'
+
+services:
+  # PostgreSQL Database
+  postgres:
+    image: postgres:15-alpine
+    container_name: bras-postgres-dev
+    environment:
+      POSTGRES_DB: bras_dev
+      POSTGRES_USER: bras_user
+      POSTGRES_PASSWORD: dev_password
+    ports:
+      - "5432:5432"
+    volumes:
+      - postgres_data_dev:/var/lib/postgresql/data
+    networks:
+      - bras-network
+
+  # Redis Cache
+  redis:
+    image: redis:7-alpine
+    container_name: bras-redis-dev
+    ports:
+      - "6379:6379"
+    volumes:
+      - redis_data_dev:/data
+    networks:
+      - bras-network
+
+  # Qdrant Vector DB
+  qdrant:
+    image: qdrant/qdrant:latest
+    container_name: bras-qdrant-dev
+    ports:
+      - "6333:6333"
+      - "6334:6334"
+    volumes:
+      - qdrant_data_dev:/qdrant/storage
+    networks:
+      - bras-network
+
+  # Prefect Server
+  prefect:
+    image: prefecthq/prefect:2-latest
+    container_name: bras-prefect-dev
+    environment:
+      PREFECT_SERVER_API_HOST: 0.0.0.0
+      PREFECT_API_DATABASE_CONNECTION_URL: postgresql+asyncpg://bras_user:dev_password@postgres:5432/bras_dev
+    ports:
+      - "4200:4200"
+    depends_on:
+      - postgres
+    networks:
+      - bras-network
+    command: prefect server start
+
+  # Backend API
+  backend:
+    build:
+      context: ./backend
+      dockerfile: Dockerfile.dev
+    container_name: bras-backend-dev
+    environment:
+      DATABASE_URL: postgresql://bras_user:dev_password@postgres:5432/bras_dev
+      REDIS_URL: redis://redis:6379
+      QDRANT_URL: http://qdrant:6333
+      PREFECT_API_URL: http://prefect:4200/api
+      OPENAI_API_KEY: ${OPENAI_API_KEY}
+      ENV: development
+    ports:
+      - "8000:8000"
+    volumes:
+      - ./backend:/app
+      - backend_cache_dev:/app/.cache
+    depends_on:
+      - postgres
+      - redis
+      - qdrant
+      - prefect
+    networks:
+      - bras-network
+    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
+
+  # Frontend
+  frontend:
+    build:
+      context: ./frontend
+      dockerfile: Dockerfile.dev
+    container_name: bras-frontend-dev
+    environment:
+      VITE_API_URL: http://localhost:8000
+      VITE_WS_URL: ws://localhost:8000
+    ports:
+      - "9000:9000"
+    volumes:
+      - ./frontend:/app
+      - /app/node_modules
+    depends_on:
+      - backend
+    networks:
+      - bras-network
+    command: quasar dev
+
+volumes:
+  postgres_data_dev:
+  redis_data_dev:
+  qdrant_data_dev:
+  backend_cache_dev:
+
+networks:
+  bras-network:
+    driver: bridge
+```
+
+### Start Development Environment
+
+```bash
+# Start all services
+docker-compose -f docker-compose.dev.yml up -d
+
+# Check logs
+docker-compose -f docker-compose.dev.yml logs -f
+
+# Run database migrations
+docker-compose exec backend alembic upgrade head
+
+# Create first user
+docker-compose exec backend python scripts/create_admin_user.py
+
+# Access services:
+# - Frontend: http://localhost:9000
+# - Backend API: http://localhost:8000
+# - API Docs: http://localhost:8000/docs
+# - Prefect UI: http://localhost:4200
+```
+
+---
+
+## Backend Dockerfile
+
+```dockerfile
+# backend/Dockerfile.dev
+FROM python:3.11-slim
+
+WORKDIR /app
+
+# Install system dependencies
+RUN apt-get update && apt-get install -y \
+    gcc \
+    postgresql-client \
+    && rm -rf /var/lib/apt/lists/*
+
+# Install Python dependencies
+COPY requirements.txt .
+RUN pip install --no-cache-dir -r requirements.txt
+
+# Copy application code
+COPY . .
+
+# Expose port
+EXPOSE 8000
+
+# Development command (overridden in docker-compose)
+CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
+```
+
+```dockerfile
+# backend/Dockerfile.prod
+FROM python:3.11-slim
+
+WORKDIR /app
+
+# Install system dependencies
+RUN apt-get update && apt-get install -y \
+    gcc \
+    postgresql-client \
+    && rm -rf /var/lib/apt/lists/*
+
+# Install Python dependencies
+COPY requirements.txt .
+RUN pip install --no-cache-dir -r requirements.txt
+
+# Copy application code
+COPY . .
+
+# Create non-root user
+RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
+USER appuser
+
+# Expose port
+EXPOSE 8000
+
+# Production command
+CMD ["gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]
+```
+
+### Backend requirements.txt
+
+```txt
+# Core
+fastapi==0.110.0
+uvicorn[standard]==0.27.0
+gunicorn==21.2.0
+python-multipart==0.0.9
+
+# Database
+sqlalchemy==2.0.27
+alembic==1.13.1
+psycopg2-binary==2.9.9
+asyncpg==0.29.0
+
+# Validation
+pydantic==2.6.1
+pydantic-settings==2.1.0
+pydantic-ai==0.0.13
+
+# AI
+openai==1.12.0
+anthropic==0.18.1
+
+# Workflow
+prefect==2.16.0
+
+# Vector DB
+qdrant-client==1.7.3
+
+# Cache
+redis==5.0.1
+hiredis==2.3.2
+
+# Tree structure
+# RefMemTree - add actual package name when available
+
+# Utils
+python-jose[cryptography]==3.3.0
+passlib[bcrypt]==1.7.4
+python-dotenv==1.0.1
+httpx==0.26.0
+
+# WebSocket
+websockets==12.0
+```
+
+---
+
+## Frontend Dockerfile
+
+```dockerfile
+# frontend/Dockerfile.dev
+FROM node:20-alpine
+
+WORKDIR /app
+
+# Copy package files
+COPY package*.json ./
+
+# Install dependencies
+RUN npm install
+
+# Copy application code
+COPY . .
+
+# Expose port
+EXPOSE 9000
+
+# Development command
+CMD ["npm", "run", "dev"]
+```
+
+```dockerfile
+# frontend/Dockerfile.prod
+FROM node:20-alpine as build
+
+WORKDIR /app
+
+# Copy package files
+COPY package*.json ./
+
+# Install dependencies
+RUN npm ci --only=production
+
+# Copy application code
+COPY . .
+
+# Build application
+RUN npm run build
+
+# Production stage
+FROM nginx:alpine
+
+# Copy built files
+COPY --from=build /app/dist/spa /usr/share/nginx/html
+
+# Copy nginx config
+COPY nginx.conf /etc/nginx/conf.d/default.conf
+
+EXPOSE 80
+
+CMD ["nginx", "-g", "daemon off;"]
+```
+
+### Frontend nginx.conf
+
+```nginx
+server {
+    listen 80;
+    server_name _;
+
+    root /usr/share/nginx/html;
+    index index.html;
+
+    # Gzip compression
+    gzip on;
+    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
+
+    # SPA routing
+    location / {
+        try_files $uri $uri/ /index.html;
+    }
+
+    # API proxy
+    location /api {
+        proxy_pass http://backend:8000;
+        proxy_http_version 1.1;
+        proxy_set_header Upgrade $http_upgrade;
+        proxy_set_header Connection 'upgrade';
+        proxy_set_header Host $host;
+        proxy_cache_bypass $http_upgrade;
+        proxy_set_header X-Real-IP $remote_addr;
+        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
+    }
+
+    # WebSocket proxy
+    location /ws {
+        proxy_pass http://backend:8000;
+        proxy_http_version 1.1;
+        proxy_set_header Upgrade $http_upgrade;
+        proxy_set_header Connection "Upgrade";
+        proxy_set_header Host $host;
+    }
+
+    # Cache static assets
+    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
+        expires 1y;
+        add_header Cache-Control "public, immutable";
+    }
+}
+```
+
+---
+
+## Production Deployment
+
+### Production Docker Compose
+
+```yaml
+# docker-compose.prod.yml
+version: '3.8'
+
+services:
+  postgres:
+    image: postgres:15-alpine
+    container_name: bras-postgres
+    environment:
+      POSTGRES_DB: ${POSTGRES_DB}
+      POSTGRES_USER: ${POSTGRES_USER}
+      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
+    volumes:
+      - postgres_data:/var/lib/postgresql/data
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  redis:
+    image: redis:7-alpine
+    container_name: bras-redis
+    volumes:
+      - redis_data:/data
+    networks:
+      - bras-network
+    restart: unless-stopped
+    command: redis-server --appendonly yes
+
+  qdrant:
+    image: qdrant/qdrant:latest
+    container_name: bras-qdrant
+    volumes:
+      - qdrant_data:/qdrant/storage
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  prefect:
+    image: prefecthq/prefect:2-latest
+    container_name: bras-prefect
+    environment:
+      PREFECT_SERVER_API_HOST: 0.0.0.0
+      PREFECT_API_DATABASE_CONNECTION_URL: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
+    depends_on:
+      - postgres
+    networks:
+      - bras-network
+    restart: unless-stopped
+    command: prefect server start
+
+  backend:
+    build:
+      context: ./backend
+      dockerfile: Dockerfile.prod
+    container_name: bras-backend
+    environment:
+      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
+      REDIS_URL: redis://redis:6379
+      QDRANT_URL: http://qdrant:6333
+      PREFECT_API_URL: http://prefect:4200/api
+      OPENAI_API_KEY: ${OPENAI_API_KEY}
+      ENV: production
+      SECRET_KEY: ${SECRET_KEY}
+    depends_on:
+      - postgres
+      - redis
+      - qdrant
+      - prefect
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  frontend:
+    build:
+      context: ./frontend
+      dockerfile: Dockerfile.prod
+    container_name: bras-frontend
+    depends_on:
+      - backend
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  nginx:
+    image: nginx:alpine
+    container_name: bras-nginx
+    ports:
+      - "80:80"
+      - "443:443"
+    volumes:
+      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
+      - ./nginx/ssl:/etc/nginx/ssl
+      - ./nginx/logs:/var/log/nginx
+    depends_on:
+      - frontend
+      - backend
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  # Monitoring
+  prometheus:
+    image: prom/prometheus:latest
+    container_name: bras-prometheus
+    volumes:
+      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
+      - prometheus_data:/prometheus
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+  grafana:
+    image: grafana/grafana:latest
+    container_name: bras-grafana
+    environment:
+      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
+    volumes:
+      - grafana_data:/var/lib/grafana
+      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
+    ports:
+      - "3000:3000"
+    networks:
+      - bras-network
+    restart: unless-stopped
+
+volumes:
+  postgres_data:
+  redis_data:
+  qdrant_data:
+  prometheus_data:
+  grafana_data:
+
+networks:
+  bras-network:
+    driver: bridge
+```
+
+### Production Nginx Config
+
+```nginx
+# nginx/nginx.conf
+upstream backend {
+    least_conn;
+    server backend:8000 max_fails=3 fail_timeout=30s;
+}
+
+upstream frontend {
+    server frontend:80;
+}
+
+# HTTP to HTTPS redirect
+server {
+    listen 80;
+    server_name yourdomain.com www.yourdomain.com;
+    
+    location /.well-known/acme-challenge/ {
+        root /var/www/certbot;
+    }
+    
+    location / {
+        return 301 https://$server_name$request_uri;
+    }
+}
+
+# HTTPS Server
+server {
+    listen 443 ssl http2;
+    server_name yourdomain.com www.yourdomain.com;
+
+    # SSL Configuration
+    ssl_certificate /etc/nginx/ssl/fullchain.pem;
+    ssl_certificate_key /etc/nginx/ssl/privkey.pem;
+    ssl_protocols TLSv1.2 TLSv1.3;
+    ssl_ciphers HIGH:!aNULL:!MD5;
+    ssl_prefer_server_ciphers on;
+
+    # Security headers
+    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
+    add_header X-Frame-Options "SAMEORIGIN" always;
+    add_header X-Content-Type-Options "nosniff" always;
+    add_header X-XSS-Protection "1; mode=block" always;
+
+    # Logging
+    access_log /var/log/nginx/access.log;
+    error_log /var/log/nginx/error.log;
+
+    # Client body size
+    client_max_body_size 50M;
+
+    # Frontend
+    location / {
+        proxy_pass http://frontend;
+        proxy_set_header Host $host;
+        proxy_set_header X-Real-IP $remote_addr;
+        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
+        proxy_set_header X-Forwarded-Proto $scheme;
+    }
+
+    # Backend API
+    location /api {
+        proxy_pass http://backend;
+        proxy_http_version 1.1;
+        proxy_set_header Host $host;
+        proxy_set_header X-Real-IP $remote_addr;
+        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
+        proxy_set_header X-Forwarded-Proto $scheme;
+        
+        # Timeouts for long-running AI requests
+        proxy_connect_timeout 300s;
+        proxy_send_timeout 300s;
+        proxy_read_timeout 300s;
+    }
+
+    # WebSocket
+    location /ws {
+        proxy_pass http://backend;
+        proxy_http_version 1.1;
+        proxy_set_header Upgrade $http_upgrade;
+        proxy_set_header Connection "Upgrade";
+        proxy_set_header Host $host;
+        proxy_set_header X-Real-IP $remote_addr;
+        
+        # WebSocket timeouts
+        proxy_connect_timeout 7d;
+        proxy_send_timeout 7d;
+        proxy_read_timeout 7d;
+    }
+
+    # Prefect UI (optional, for admin access)
+    location /prefect {
+        proxy_pass http://prefect:4200;
+        proxy_set_header Host $host;
+        proxy_set_header X-Real-IP $remote_addr;
+    }
+}
+```
+
+### Deployment Script
+
+```bash
+#!/bin/bash
+# deploy.sh
+
+set -e
+
+echo "üöÄ Deploying Business Requirements AI System"
+
+# Load environment variables
+source .env.prod
+
+# Pull latest code
+echo "üì¶ Pulling latest code..."
+git pull origin main
+
+# Build images
+echo "üî® Building Docker images..."
+docker-compose -f docker-compose.prod.yml build
+
+# Stop old containers
+echo "üõë Stopping old containers..."
+docker-compose -f docker-compose.prod.yml down
+
+# Start new containers
+echo "‚ñ∂Ô∏è  Starting new containers..."
+docker-compose -f docker-compose.prod.yml up -d
+
+# Wait for database
+echo "‚è≥ Waiting for database..."
+sleep 10
+
+# Run migrations
+echo "üîÑ Running database migrations..."
+docker-compose -f docker-compose.prod.yml exec -T backend alembic upgrade head
+
+# Check health
+echo "üè• Checking service health..."
+curl -f http://localhost/api/health || exit 1
+
+echo "‚úÖ Deployment completed successfully!"
+```
+
+---
+
+## Database Migrations
+
+### Alembic Configuration
+
+```python
+# backend/alembic/env.py
+from logging.config import fileConfig
+from sqlalchemy import engine_from_config, pool
+from alembic import context
+from db.models import Base
+import os
+
+# Load environment
+config = context.config
+config.set_main_option('sqlalchemy.url', os.getenv('DATABASE_URL'))
+
+# Interpret the config file for Python logging
+if config.config_file_name is not None:
+    fileConfig(config.config_file_name)
+
+target_metadata = Base.metadata
+
+def run_migrations_online():
+    connectable = engine_from_config(
+        config.get_section(config.config_ini_section),
+        prefix="sqlalchemy.",
+        poolclass=pool.NullPool,
+    )
+
+    with connectable.connect() as connection:
+        context.configure(
+            connection=connection,
+            target_metadata=target_metadata
+        )
+
+        with context.begin_transaction():
+            context.run_migrations()
+
+run_migrations_online()
+```
+
+### Create Migration
+
+```bash
+# Create new migration
+docker-compose exec backend alembic revision --autogenerate -m "description"
+
+# Apply migrations
+docker-compose exec backend alembic upgrade head
+
+# Rollback
+docker-compose exec backend alembic downgrade -1
+```
+
+---
+
+## Monitoring Setup
+
+### Prometheus Configuration
+
+```yaml
+# monitoring/prometheus.yml
+global:
+  scrape_interval: 15s
+  evaluation_interval: 15s
+
+scrape_configs:
+  - job_name: 'backend'
+    static_configs:
+      - targets: ['backend:8000']
+    metrics_path: '/metrics'
+
+  - job_name: 'postgres'
+    static_configs:
+      - targets: ['postgres:5432']
+
+  - job_name: 'redis'
+    static_configs:
+      - targets: ['redis:6379']
+```
+
+### Backend Metrics Endpoint
+
+```python
+# backend/api/v1/metrics.py
+from fastapi import APIRouter
+from prometheus_client import Counter, Histogram, generate_latest
+
+router = APIRouter()
+
+# Metrics
+api_requests = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint'])
+api_latency = Histogram('api_latency_seconds', 'API latency')
+ai_calls = Counter('ai_calls_total', 'Total AI agent calls', ['agent_type'])
+ai_cost = Counter('ai_cost_total', 'Total AI cost in USD')
+
+@router.get('/metrics')
+def metrics():
+    return generate_latest()
+```
+
+---
+
+## Backup Strategy
+
+### Database Backup Script
+
+```bash
+#!/bin/bash
+# scripts/backup.sh
+
+BACKUP_DIR="/backups"
+DATE=$(date +%Y%m%d_%H%M%S)
+BACKUP_FILE="$BACKUP_DIR/backup_$DATE.sql"
+
+# Create backup
+docker-compose exec -T postgres pg_dump -U bras_user bras_prod > $BACKUP_FILE
+
+# Compress
+gzip $BACKUP_FILE
+
+# Upload to S3 (optional)
+aws s3 cp $BACKUP_FILE.gz s3://your-bucket/backups/
+
+# Keep only last 7 days
+find $BACKUP_DIR -name "backup_*.sql.gz" -mtime +7 -delete
+
+echo "Backup completed: $BACKUP_FILE.gz"
+```
+
+### Automated Backup with Cron
+
+```bash
+# Add to crontab
+0 2 * * * /path/to/scripts/backup.sh
+```
+
+---
+
+## CI/CD Pipeline (GitHub Actions)
+
+```yaml
+# .github/workflows/deploy.yml
+name: Deploy
+
+on:
+  push:
+    branches: [main]
+
+jobs:
+  test:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v3
+      
+      - name: Run backend tests
+        run: |
+          cd backend
+          pip install -r requirements.txt
+          pytest
+      
+      - name: Run frontend tests
+        run: |
+          cd frontend
+          npm install
+          npm run test
+
+  deploy:
+    needs: test
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v3
+      
+      - name: Deploy to production
+        uses: appleboy/ssh-action@master
+        with:
+          host: ${{ secrets.HOST }}
+          username: ${{ secrets.USERNAME }}
+          key: ${{ secrets.SSH_KEY }}
+          script: |
+            cd /opt/bras
+            ./deploy.sh
+```
+
+---
+
+## Health Checks
+
+```python
+# backend/api/v1/health.py
+from fastapi import APIRouter, Depends
+from sqlalchemy.orm import Session
+from db.session import get_db
+import redis
+import httpx
+
+router = APIRouter()
+
+@router.get('/health')
+async def health_check(db: Session = Depends(get_db)):
+    checks = {
+        'status': 'healthy',
+        'services': {}
+    }
+    
+    # Database
+    try:
+        db.execute('SELECT 1')
+        checks['services']['database'] = 'up'
+    except Exception as e:
+        checks['services']['database'] = 'down'
+        checks['status'] = 'unhealthy'
+    
+    # Redis
+    try:
+        r = redis.Redis(host='redis', port=6379)
+        r.ping()
+        checks['services']['redis'] = 'up'
+    except Exception as e:
+        checks['services']['redis'] = 'down'
+        checks['status'] = 'unhealthy'
+    
+    # Qdrant
+    try:
+        async with httpx.AsyncClient() as client:
+            response = await client.get('http://qdrant:6333/health')
+            checks['services']['qdrant'] = 'up' if response.status_code == 200 else 'down'
+    except Exception as e:
+        checks['services']['qdrant'] = 'down'
+    
+    return checks
+```
+
+---
+
+–¢–æ–≤–∞ –µ deployment guide-—ä—Ç. –°–µ–≥–∞ —â–µ —Å—ä–∑–¥–∞–º —Ñ–∏–Ω–∞–ª–µ–Ω –æ–±–æ–±—â–∞–≤–∞—â –¥–æ–∫—É–º–µ–Ω—Ç.